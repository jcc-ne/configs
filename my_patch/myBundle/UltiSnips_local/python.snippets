snippet __main__ " main " b
if __name__ == "__main__":
endsnippet

snippet super
    super(HogFeatSKImage, self).__init__(img)
endsnippet

snippet train_test
        X_train, X_test, y_train, y_test = train_test_split(X, y)
endsnippet

snippet version
   import sys

   sys.version_info[0] < 3:
	  def next(iter):
		 return iter.next()
endsnippet

snippet plt
	 import matplotlib.pyplot as plt
	 import matplotlib
	 matplotlib.rcParams.update({'font.size': 8})
endsnippet

snippet cmap
    m = plt.cm.ScalarMappable(cmap=CMAP)
    m.set_array(w_abs / max_)
    cbaxes = fig.add_axes([0.90, 0.1, 0.03, 0.8])
    cb = plt.colorbar(m, cax=cbaxes, use_gridspec=True)
    cb.outline.set_visible(False)
endsnippet

snippet ax
    #  fig, axes = plt.subplots(nrows=2, ncols=4)
	 fig = plt.figure()
	 ax = fig.add_subplot(121)
endsnippet

snippet plt3d
	 from mpl_toolkits.mplot3d import Axes3D
	 fig = plt.figure()
	 ax2 = fig.add_subplot(111, projection='3d')
	 im = ax2.imshow(data, cmap=plt.cm.jet, vmax=data.max(), interpolation='nearest')
	 fig.colorbar(im)

	 x_res = 10
	 y_res = 10
	 xx, yy = np.meshgrid(np.linspace(0,1,x_res+1), np.linspace(0,1,y_res+1))
	 X = xx
	 Y = yy
	 Z = np.ones((x_res + 1, y_res + 1))
	 data = np.reshape(range(16), (4, 4)
	 ax2.plot_surface(X, Y, Z, rstride=1, cstride=1,
				cmap=plt.cm.jet,
				facecolors=plt.cm.jet(data), shade=False)

endsnippet

snippet unittest
import _add_test_path  # noqa
import unittest
import snapshottest

class TestCase(snapshottest.TestCase):
	@classmethod
	def setUpClass(cls):
		super(TestCase, cls).setUpClass()

	def setUp(self):
		pass
	def test_np_equal(self):
		self.assertTrue(
			np.equal(
				np.array([1,2,3]),
				np.array([1,3])
			).all()
			)
	def test_snapshot(self):
		d = [1, 2, 3]
		self.assertMatchSnapshot(d)

	def test_snapshot_nparray(self):
		import numpy as np
		d = np.array([1, 2, 3])
		self.assertMatchSnapshotNPArray(d)

	def test_snapshot_dataframe(self):
		import pandas as pd
		df = pd.DataFrame({'b': [3, 2, 3, 4]})
		self.assertMatchSnapshotDataFrame(df)

	#  @unittest.skip("demonstrating skipping")
	def test_skipped(self):
		self.assertEqual(1, 2)
	def tearDown(self):
		pass
if __name__ == "__main__":
	try:
		if __IPYTHON__:
			suite = unittest.TestLoader().loadTestsFromTestCase(
					TestCase)
			unittest.TextTestRunner(verbosity=2).run(suite)
	except NameError:
		unittest.main()
endsnippet

snippet unittest2

# -------- TEST SUITE -------
if __name__ == "__main__":
    import unittest

    class TestCase(unittest.TestCase):
        def test_filename(self):
            filename = 'foo.bar'
            print(filename)
            self.assertRegex(add_timestamp(filename), r'foo-\d+\.\d+\.bar')

        def test_filepath(self):
            filename = './foo.bar'
            print(filename)
            self.assertRegex(add_timestamp(filename), r'\./foo-\d+\.\d+\.bar')

        def test_filepath_1(self):
            filename = '/home/user/proj/foo.bar'
            print(filename)
            self.assertRegex(add_timestamp(filename),
                             r'/home/user/proj/foo-\d+\.\d+\.bar')

        def test_filepath_no_ext(self):
            filename = '../user/proj/foo'
            print(filename)
            self.assertRegex(add_timestamp(filename),
                             r'../user/proj/foo-\d+\.\d+')

    suite = unittest.TestLoader().loadTestsFromName(__name__)
    unittest.TextTestRunner(verbosity=2).run(suite)
endsnippet

snippet subprocess
	import subprocess
	# output = subprocess.check_output(["", ""])
	proc = subprocess.Popen(["$1", "$2"], stdout=subprocess.PIPE, shell=True)
	(out, err) = proc.communicate()
endsnippet

snippet logging
import logging
import sys
logging.basicConfig(level=logging.DEBUG, stream=sys.stdout)
logger = logging.getLogger(__name__)
endsnippet

snippet argparse
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('-t', '--train_set', nargs='+', default=[],
                        help="other pairs dataframe for training")
    subparser = parser.add_subparsers(
        dest="subcommand",
        help="subcommand: predict or train")

    parser_train = subparser.add_parser('train', help="call train api")
    parser_train.add_argument('json_data_file',
                              help="ansible data in json format")
    parser_train.add_argument('-q', '--quiet', action="store_true",
                              default=False, help="only print output")

    args = parser.parse_args()
endsnippet

snippet reqparse
from flask_restful import Resource, reqparse, inputs
    def __init__(self):
        self.reqparse = reqparse.RequestParser()
        self.reqparse.add_argument('data', type=str,
                                   required=True,
                                   help='need input data',
                                   location='values')
        self.reqparse.add_argument('reload_model', type=inputs.boolean,
                                   action="store_true",
                                   required=False,
                                   default=False,
                                   help='need input data',
                                   location='values')
endsnippet

snippet mp4

import matplotlib.animation as animation

FFMpegWriter = animation.writers['ffmpeg']
metadata = dict(title='{}'.format(MODEL_NAME), artist='aurima',
                comment='movies of vis data after classifier detection')
				writer = FFMpegWriter(fps=4, metadata=metadata)
				fig = plt.figure(figsize=IMAGE_SIZE)
writer.setup(fig, "{}.mp4".format(MODEL_NAME), 100)

for i, image_np in enumerate(images):
	vis_util.visualize_boxes_and_labels_on_image_array(
					image_np,
					np.squeeze(boxes_n[i]),
					np.squeeze(classes_n[i]).astype(np.int32),
					np.squeeze(scores_n[i]),
					category_index,
					use_normalized_coordinates=True,
					line_thickness=4)
	plt.imshow(image_np)
	writer.grab_frame()
writer.finish()
endsnippet

snippet ipython_mp4
import io
import base64
from IPython.display import HTML

video = io.open("{}.mp4".format(MODEL_NAME), 'r+b').read()
encoded = base64.b64encode(video)
HTML(data='''<video alt="test" width="850" controls>
                <source src="data:video/mp4;base64,{0}" type="video/mp4" />
				             </video>'''.format(encoded.decode('ascii')))
endsnippet

###########################################################################
#                            TEXTMATE SNIPPETS                            #
###########################################################################

#! header
snippet #! "Shebang header for python scripts" b
#!/usr/bin/env python
# -*- coding: utf-8 -*-
$0
endsnippet

snippet ifmain0 "ifmain" b
if __name__ == `!p snip.rv = get_quoting_style(snip)`__main__`!p snip.rv = get_quoting_style(snip)`:
	${1:${VISUAL:main()}}
endsnippet

snippet ifmain
if __name__ == "__main__":
    import argparse

    logging.basicConfig()
    logger = logging.getLogger('root')
    logger.setLevel(logging.DEBUG)

    parser = argparse.ArgumentParser()
    parser.add_argument('input_path', default=None,
                        help="input filepath ad data source for fakeserial")

    args = parser.parse_args()
    main(args.input_path)
endsnippet

snippet with "with" b
with ${1:expr}`!p snip.rv = " as " if t[2] else ""`${2:var}:
	${3:${VISUAL:pass}}
$0
endsnippet

snippet for "for loop" b
for ${1:item} in ${2:iterable}:
	${3:${VISUAL:pass}}
endsnippet

##########
# COMMON #
##########

# The smart def and smart class snippets use a global option called
# "g:ultisnips_python_style" which, if set to "doxygen" will use doxygen
# style comments in docstrings.

global !p

NORMAL  = 0x1
DOXYGEN = 0x2
SPHINX  = 0x3
GOOGLE  = 0x4
NUMPY   = 0x5
JEDI    = 0x6

SINGLE_QUOTES = "'"
DOUBLE_QUOTES = '"'


class Arg(object):
	def __init__(self, arg):
		self.arg = arg
		self.name = arg.split('=')[0].strip()

	def __str__(self):
		return self.name

	def __unicode__(self):
		return self.name

	def is_kwarg(self):
		return '=' in self.arg


def get_args(arglist):
	args = [Arg(arg) for arg in arglist.split(',') if arg]
	args = [arg for arg in args if arg.name != 'self']

	return args


def get_quoting_style(snip):
	style = snip.opt("g:ultisnips_python_quoting_style", "double")
	if style == 'single':
		return SINGLE_QUOTES
	return DOUBLE_QUOTES

def triple_quotes(snip):
	style = snip.opt("g:ultisnips_python_triple_quoting_style")
	if not style:
		return get_quoting_style(snip) * 3
	return (SINGLE_QUOTES if style == 'single' else DOUBLE_QUOTES) * 3

def triple_quotes_handle_trailing(snip, quoting_style):
	"""
	Generate triple quoted strings and handle any trailing quote char,
	which might be there from some autoclose/autopair plugin,
	i.e. when expanding ``"|"``.
	"""
	if not snip.c:
		# Do this only once, otherwise the following error would happen:
		# RuntimeError: The snippets content did not converge: â€¦
		_, col = vim.current.window.cursor
		line = vim.current.line

		# Handle already existing quote chars after the trigger.
		_ret = quoting_style * 3
		while True:
			try:
				nextc = line[col]
			except IndexError:
				break
			if nextc == quoting_style and len(_ret):
				_ret = _ret[1:]
				col = col+1
			else:
				break
		snip.rv = _ret
	else:
		snip.rv = snip.c

def get_style(snip):
	style = snip.opt("g:ultisnips_python_style", "normal")

	if    style == "doxygen": return DOXYGEN
	elif  style == "sphinx": return SPHINX
	elif  style == "google": return GOOGLE
	elif  style == "numpy": return NUMPY
	elif  style == "jedi": return JEDI
	else: return NORMAL


def format_arg(arg, style):
	if style == DOXYGEN:
		return "@param %s TODO" % arg
	elif style == SPHINX:
		return ":param %s: TODO" % arg
	elif style == NORMAL:
		return ":%s: TODO" % arg
	elif style == GOOGLE:
		return "%s (TODO): TODO" % arg
	elif style == JEDI:
		return ":type %s: TODO" % arg
	elif style == NUMPY:
		return "%s : TODO" % arg


def format_return(style):
	if style == DOXYGEN:
		return "@return: TODO"
	elif style in (NORMAL, SPHINX, JEDI):
		return ":returns: TODO"
	elif style == GOOGLE:
		return "Returns: TODO"


def write_docstring_args(args, snip):
	if not args:
		snip.rv += ' {0}'.format(triple_quotes(snip))
		return

	snip.rv += '\n' + snip.mkline('', indent='')

	style = get_style(snip)

	if style == GOOGLE:
		write_google_docstring_args(args, snip)
	elif style == NUMPY:
		write_numpy_docstring_args(args, snip)
	else:
		for arg in args:
			snip += format_arg(arg, style)


def write_google_docstring_args(args, snip):
	kwargs = [arg for arg in args if arg.is_kwarg()]
	args = [arg for arg in args if not arg.is_kwarg()]

	if args:
		snip += "Args:"
		snip.shift()
		for arg in args:
			snip += format_arg(arg, GOOGLE)
		snip.unshift()
		snip.rv += '\n' + snip.mkline('', indent='')

	if kwargs:
		snip += "Kwargs:"
		snip.shift()
		for kwarg in kwargs:
			snip += format_arg(kwarg, GOOGLE)
		snip.unshift()
		snip.rv += '\n' + snip.mkline('', indent='')


def write_numpy_docstring_args(args, snip):
	if args:
		snip += "Parameters"
		snip += "----------"

	kwargs = [arg for arg in args if arg.is_kwarg()]
	args = [arg for arg in args if not arg.is_kwarg()]

	if args:
		for arg in args:
			snip += format_arg(arg, NUMPY)
	if kwargs:
		for kwarg in kwargs:
			snip += format_arg(kwarg, NUMPY) + ', optional'
	snip.rv += '\n' + snip.mkline('', indent='')


def write_init_body(args, parents, snip):
	parents = [p.strip() for p in parents.split(",")]
	parents = [p for p in parents if p != 'object']

	for p in parents:
		snip += p + ".__init__(self)"

	if parents:
		snip.rv += '\n' + snip.mkline('', indent='')

	for arg in args:
		snip += "self._%s = %s" % (arg, arg)


def write_slots_args(args, snip):
	quote = get_quoting_style(snip)
	arg_format = quote + '_%s' + quote
	args = [arg_format % arg for arg in args]
	snip += '__slots__ = (%s,)' % ', '.join(args)


def write_function_docstring(t, snip):
	"""
	Writes a function docstring with the current style.

	:param t: The values of the placeholders
	:param snip: UltiSnips.TextObjects.SnippetUtil object instance
	"""
	snip.rv = ""
	snip >> 1

	args = get_args(t[2])
	if args:
		write_docstring_args(args, snip)

	style = get_style(snip)

	if style == NUMPY:
		snip += 'Returns'
		snip += '-------'
		snip += 'TODO'
	else:
		snip += format_return(style)
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += triple_quotes(snip)

def get_dir_and_file_name(snip):
	return os.getcwd().split(os.sep)[-1] + '.' + snip.basename

endglobal

########################################
# Class & Special Method Name Snippets #
########################################

snippet class "class with docstrings" b
class ${1:MyClass}(${2:object}):

	`!p snip.rv = triple_quotes(snip)`${3:Docstring for $1. }`!p snip.rv = triple_quotes(snip)`

	def __init__(self$4):
		`!p snip.rv = triple_quotes(snip)`${5:TODO: to be defined1.}`!p
snip.rv = ""
snip >> 2

args = get_args(t[4])

write_docstring_args(args, snip)
if args:
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += '{0}'.format(triple_quotes(snip))

write_init_body(args, t[2], snip)
`
		$0
endsnippet


snippet slotclass "class with slots and docstrings" b
class ${1:MyClass}(${2:object}):

	`!p snip.rv = triple_quotes(snip)`${3:Docstring for $1. }`!p snip.rv = triple_quotes(snip)`
`!p
snip >> 1
args = get_args(t[4])
write_slots_args(args, snip)
`

	def __init__(self$4):
		`!p snip.rv = triple_quotes(snip)`${5:TODO: to be defined.}`!p
snip.rv = ""
snip >> 2

args = get_args(t[4])

write_docstring_args(args, snip)
if args:
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += triple_quotes(snip)

write_init_body(args, t[2], snip)
`
		$0
endsnippet


snippet contain "methods for emulating a container type" b
def __len__(self):
	${1:pass}

def __getitem__(self, key):
	${2:pass}

def __setitem__(self, key, value):
	${3:pass}

def __delitem__(self, key):
	${4:pass}

def __iter__(self):
	${5:pass}

def __reversed__(self):
	${6:pass}

def __contains__(self, item):
	${7:pass}
endsnippet


snippet context "context manager methods" b
def __enter__(self):
	${1:pass}

def __exit__(self, exc_type, exc_value, traceback):
	${2:pass}
endsnippet


snippet attr "methods for customizing attribute access" b
def __getattr__(self, name):
	${1:pass}

def __setattr__(self, name, value):
	${2:pass}

def __delattr__(self, name):
	${3:pass}
endsnippet


snippet desc "methods implementing descriptors" b
def __get__(self, instance, owner):
	${1:pass}

def __set__(self, instance, value):
	${2:pass}

def __delete__(self, instance):
	${3:pass}
endsnippet


snippet cmp "methods implementing rich comparison"
def __eq__(self, other):
	${1:pass}

def __ne__(self, other):
	${2:pass}

def __lt__(self, other):
	${3:pass}

def __le__(self, other):
	${4:pass}

def __gt__(self, other):
	${5:pass}

def __ge__(self, other):
	${6:pass}

def __cmp__(self, other):
	${7:pass}
endsnippet


snippet repr "methods implementing string representation"
def __repr__(self):
	${1:pass}

def __str__(self):
	${2:pass}

def __unicode__(self):
	${3:pass}
endsnippet


# note: reflected operands and augmented arithmeitc assignements have been
# intentionally ommited to reduce verbosity.
snippet numeric "methods for emulating a numeric type" b
def __add__(self, other):
	${1:pass}

def __sub__(self, other):
	${2:pass}

def __mul__(self, other):
	${3:pass}

def __div__(self, other):
	${4:pass}

def __truediv__(self, other):
	${5:pass}

def __floordiv__(self, other):
	${6:pass}


def __mod__(self, other):
	${7:pass}

def __divmod__(self, other):
	${8:pass}

def __pow__(self, other):
	${9:pass}


def __lshift__(self, other):
	${10:pass}

def __rshift__(self, other):
	${11:pass}

def __and__(self, other):
	${12:pass}

def __xor__(self, other):
	${13:pass}

def __or__(self, other):
	${14:pass}


def __neg__(self):
	${15:pass}

def __pos__(self):
	${16:pass}

def __abs__(self):
	${17:pass}

def __invert__(self):
	${18:pass}


def __complex__(self):
	${19:pass}

def __int__(self):
	${20:pass}

def __long__(self):
	${21:pass}

def __float__(self):
	${22:pass}


def __oct__(self):
	${22:pass}

def __hex__(self):
	${23:pass}


def __index__(self):
	${24:pass}

def __coerce__(self, other):
	${25:pass}
endsnippet

snippet deff
def ${1:fname}(`!p snip.rv = vim.eval('indent(".") ? "self" : ""')`$2):
	$0
endsnippet

snippet def "function with docstrings" b
def ${1:function}(`!p
if snip.indent:
	snip.rv = 'self' + (", " if len(t[2]) else "")`${2:arg1}):
	`!p snip.rv = triple_quotes(snip)`${4:TODO: Docstring for $1.}`!p
write_function_docstring(t, snip) `
	${5:${VISUAL:pass}}
endsnippet


snippet defc "class method with docstrings" b
@classmethod
def ${1:function}(`!p
if snip.indent:
	snip.rv = 'cls' + (", " if len(t[2]) else "")`${2:arg1}):
	`!p snip.rv = triple_quotes(snip)`${4:TODO: Docstring for $1.}`!p
write_function_docstring(t, snip) `
	${5:${VISUAL:pass}}
endsnippet


snippet defs "static method with docstrings" b
@staticmethod
def ${1:function}(${2:arg1}):
	`!p snip.rv = triple_quotes(snip)`${4:TODO: Docstring for $1.}`!p
write_function_docstring(t, snip) `
	${5:${VISUAL:pass}}
endsnippet


# doesn't expand when there is a word in front
snippet /(^|(?<=\W))\./ "self." r
self.
endsnippet

snippet from "from module import name" b
from ${1:module} import ${2:Stuff}
endsnippet


##############
# PROPERTIES #
##############
snippet roprop "Read Only Property" b
@property
def ${1:name}(self):
	${2:return self._$1}$0
endsnippet

snippet rwprop "Read write property" b
def ${1:name}():
	`!p snip.rv = triple_quotes(snip) if t[2] else ''
`${2:TODO: Docstring for $1.}`!p
if t[2]:
	snip >> 1

	style = get_style(snip)
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += format_return(style)
	snip.rv += '\n' + snip.mkline('', indent='')
	snip += triple_quotes(snip)
else:
	snip.rv = ""`
	def fget(self):
		return self._$1$0

	def fset(self, value):
		self._$1 = value
	return locals()

$1 = property(**$1(), doc=$1.__doc__)
endsnippet


####################
# If / Else / Elif #
####################
snippet if "If" b
if ${1:condition}:
	${2:${VISUAL:pass}}
endsnippet

snippet ife "If / Else" b
if ${1:condition}:
	${2:${VISUAL:pass}}
else:
	${3:pass}
endsnippet

snippet ifee "If / Elif / Else" b
if ${1:condition}:
	${2:${VISUAL:pass}}
elif ${3:condition}:
	${4:pass}
else:
	${5:pass}
endsnippet


##########################
# Try / Except / Finally #
##########################
snippet try "Try / Except" b
try:
	${1:${VISUAL:pass}}
except ${2:Exception} as ${3:e}:
	${4:raise $3}
endsnippet

snippet trye "Try / Except / Else" b
try:
	${1:${VISUAL:pass}}
except ${2:Exception} as ${3:e}:
	${4:raise $3}
else:
	${5:pass}
endsnippet

snippet tryf "Try / Except / Finally" b
try:
	${1:${VISUAL:pass}}
except ${2:Exception} as ${3:e}:
	${4:raise $3}
finally:
	${5:pass}
endsnippet

snippet tryef "Try / Except / Else / Finally" b
try:
	${1:${VISUAL:pass}}
except${2: ${3:Exception} as ${4:e}}:
	${5:raise}
else:
	${6:pass}
finally:
	${7:pass}
endsnippet


######################
# Assertions & Tests #
######################

snippet ae "Assert equal" b
self.assertEqual(${1:${VISUAL:first}}, ${2:second})
endsnippet

snippet at "Assert True" b
self.assertTrue(${1:${VISUAL:expression}})
endsnippet

snippet af "Assert False" b
self.assertFalse(${1:${VISUAL:expression}})
endsnippet

snippet aae "Assert almost equal" b
self.assertAlmostEqual(${1:${VISUAL:first}}, ${2:second})
endsnippet

snippet ar "Assert raises" b
self.assertRaises(${1:exception}, ${2:${VISUAL:func}}${3/.+/, /}${3:arguments})
endsnippet

snippet an "Assert is None" b
self.assertIsNone(${1:${VISUAL:expression}})
endsnippet

snippet ann "Assert is not None" b
self.assertIsNotNone(${1:${VISUAL:expression}})
endsnippet

snippet testcase "pyunit testcase" b
class Test${1:Class}(${2:unittest.TestCase}):

	`!p snip.rv = triple_quotes(snip)`${3:Test case docstring.}`!p snip.rv = triple_quotes(snip)`

	def setUp(self):
		${4:pass}

	def tearDown(self):
		${5:pass}

	def test_${6:name}(self):
		${7:${VISUAL:pass}}
endsnippet

snippet " "triple quoted string (double quotes)" b
"""
${1:${VISUAL:doc}}
`!p triple_quotes_handle_trailing(snip, '"')`
endsnippet

snippet ' "triple quoted string (single quotes)" b
'''
${1:${VISUAL:doc}}
`!p triple_quotes_handle_trailing(snip, "'")`
endsnippet

snippet doc "doc block (triple quotes)"
`!p snip.rv = triple_quotes(snip)`
${1:${VISUAL:doc}}
`!p snip.rv = triple_quotes(snip)`
endsnippet

snippet pmdoc "pocoo style module doc string" b
# -*- coding: utf-8 -*-
"""
	`!p snip.rv = get_dir_and_file_name(snip)`
	`!p snip.rv = '~' * len(get_dir_and_file_name(snip))`

	${1:DESCRIPTION}

	:copyright: (c) `date +%Y` by ${2:YOUR_NAME}.
	:license: ${3:LICENSE_NAME}, see LICENSE for more details.
"""
$0
endsnippet

snippet daytick

# ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=60))
# ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%H'))
# fig.autofmt_xdate()

def timeTicks(x, pos): 
    d = int(x / 86400e9)
    return 'day ' + str(d)

formatter = matplotlib.ticker.FuncFormatter(timeTicks 
ax.xaxis.set_major_formatter(formatter) 
endsnippet

snippet tf
import tensorflow as tf
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
endsnippet

snippet colorprint
import colorama

def _print(*args):
    text = '\t ' + colorama.Fore.GREEN
    reset = colorama.Style.RESET_ALL
    print(text, *args, reset)
endsnippet

#

snippet ipy

# <markdowncell>
# <codecell>
# <markdowncell>
# <codecell>
endsnippet

snippet ImportError
	import sys
	import os

	sys.path.append(
		os.path.join(
			os.path.dirname(os.path.realpath(__file__)),
			'..'
	))
endsnippet
snippet add_path
from _add_cur_file_parent_path import add_path; add_path(__file__)  #noqa
endsnippet

snippet re_
    re_model = re.compile(r'model_(?P<num>\d+)\.(?P<ext>(h5)|(pkl))')
endsnippet

snippet rev
    re_npy = re.compile(r"""
                        ^(?P<type>.*)       # type
                        _                   # connecting word
                        (?P<label>\d+)      # label (occupancy location)
                        (?P<version>v\d+)*  # version, optional
                        \.npy               # file ext .npy
                        """,
                        re.VERBOSE)
endsnippet

# vim:ft=snippets:

snippet cach
c = st.caching.Cache()
if c:
    print('loading data')
    if dobj.videoFrames:
        imgs = dobj.videoFrames.load(return_only=True)
        c.imgs = imgs
endsnippet

snippet tz
df.datetime.dt.tz_localize('utc').dt.tz_convert('US/Pacific')
endsnippet

snippet pytz
from pytz import timezone

now = dt.datetime.now()
# -- convert native to UTC 
# -- (note replace doesn't handle daylight savings)
now.replace(tzinfo=timezone('UTC'))

# -- convert native to UTC then conver to pacific
timezone('UTC').localize(now).astimezone(timezone('US/pacific'))
endsnippet

snippet streamlit
class PlotWidget(object):
    def __init__(self, i_radar, dobj, bool_play, skip,
                 room_plot_placeholder,
                 camera_placeholder,
                 slider_placeholder,
                 timestamp_placeholder):
        self.i_radar = i_radar
        self.skip = skip
        self.dobj = dobj
        self.bool_play = bool_play
        self.room_plot_placeholder = room_plot_placeholder
        self.camera_placeholder = camera_placeholder
        self.slider_placeholder = slider_placeholder
        self.timestamp_placeholder = timestamp_placeholder
        self.plot()

    def plot(self):
        self.radar_timestamp = self.dobj.radarTimestamps[self.i_radar]
        point_plot = self.plot_points()
        target_plot = self.plot_targets()
        room_plot = point_plot + target_plot
        self.room_plot_placeholder.altair_chart(alt.layer(room_plot))
        self.render_camera()
        self.timestamp_placeholder.text(
            f'timestamp: {self.radar_timestamp} vid {self.video_timestamp}')
        self.loop()

    def render_camera(self):
        t = self.radar_timestamp
        i_img = np.where(self.dobj.videoTimestamps > t)[0][0]
        t_img = self.dobj.videoTimestamps[i_img]
        self.video_timestamp = t_img

        img = self.dobj.videoFrames[i_img]
        if img is None or img is np.nan:
            return
        img = img[:, :, ::-1]
        self.camera_placeholder.image(img, width=500)

    def plot_points(self):
        df_points = pd.DataFrame(self.dobj.pointData[self.i_radar])
        df_points['x'] = (df_points['range'] * np.sin(df_points['angle']))
        df_points['y'] = (df_points['range'] * np.cos(df_points['angle']))
        room_plot = alt.Chart(df_points).mark_point().encode(
            x=alt.X('x:Q', scale=alt.Scale(domain=(-5, 5))),
            y=alt.Y('y:Q', scale=alt.Scale(domain=(0, 8))),
            color=alt.Color('doppler:Q', scale=alt.Scale(scheme='blueorange',
                                                         domain=(-0.5, 0.5)))
        ).properties(width=500, height=500)
        return room_plot

    def plot_targets(self):
        df = pd.DataFrame(self.dobj.targetData[self.i_radar])
        room_plot = alt.Chart(df).mark_point(
            shape=PERSON_SHAPE_STR, size=60).encode(
            x=alt.X('posX:Q', scale=alt.Scale(domain=(-5, 5))),
            y=alt.Y('posY:Q', scale=alt.Scale(domain=(0, 8))),
            color=alt.Color('tid:N', scale=alt.Scale(scheme='dark2'))
        ).properties(width=500, height=500)
        return room_plot

    def loop(self):
        if self.bool_play:
            self.i_radar += self.skip
            self.slider_placeholder.slider("idx:", 0, self.dobj.radar_data_len,
                                           value=self.i_radar)
            time.sleep(0.2)
            self.plot()
        else:
            pass
endsnippet

snippet importos
import os
import glob
from pytz import timezone
import pickle
import pandas as pd
import numpy as np
import datetime as dt
endsnippet

snippet line
	fig.add_shape(type="line",
			xref="frame #",
			yref="paper",
			x0=self.i_radar,
			y0=0,
			x1=self.i_radar,
			y1=1,
			line=dict(color='gray', 
				width=1,
				dash="solid")
			)
endsnippet
snippet altair
import altair as alt

    chart = alt.Chart(df).mark_line(clip=True).encode(
        x=alt.X('${1:index:N}',scale=alt.Scale(domain(${2:0, 100})),
			${3:axis=alt.Axis(tickCount=10, labels=False, title='title'))},
		),
        y=alt.Y('${4:mag:Q}', scale=alt.Scale(domain=(0, 100)))
    ).properties(width=500)
    placeholder_chart.altair_chart(chart)
endsnippet


snippet altair_combo
        chart = {}
        chart['heart'] = alt.Chart(df2).mark_line(
            clip=True, color='orange').encode(
                x=alt.X('ind:Q', axis=alt.Axis(tickCount=10, labels=False,
                                               title='Heart')),
                y=alt.Y('HeartBeat:Q',
                        axis=alt.Axis(title='Measure', labels=False),
                        scale=alt.Scale(domain=(-1.5, 1.5))),
            # column='variable:N',
            # color=alt.Color('variable:N', legend=None)
        ).properties(
            width=230,
            height=230
        )
        # chart['heart'] += alt.Chart(pd.DataFrame(
        #     dict(x=[7], y=[-1.2], text=[f'{self.heartrate_str}'])
        # )).mark_text(size=20, color='#DF7401').encode(x='x', y='y', text='text')
        chart['breath'] = alt.Chart(df2).mark_line(clip=True).encode(
                x=alt.X('ind:Q', axis=alt.Axis(tickCount=10, labels=False,
                                               title='Lungs')),
                y=alt.Y('BreathWave:Q',
                        axis=alt.Axis(title='Measure', labels=False),
                        scale=alt.Scale(domain=(-1.5, 1.5))),
        ).properties(
            width=230,
            height=230
        )
        # chart['breath'] += alt.Chart(pd.DataFrame(
        #     dict(x=[7], y=[-1.2], text=[f'{self.breathrate_str}'])
        # )).mark_text(size=20, color='#084B8A').encode(x='x', y='y', text='text')
        # for case in ['heart', 'breath']:
        #     lh = pd.DataFrame(
        #         {'start': [0],
        #          'end': [WIN_LEN],
        #          'lower': [self.measure_model.lower_ind[case]],
        #          'higher': [self.measure_model.higher_ind[case]]})
        #     rule_l = alt.Chart(lh).mark_rect(color='gray', opacity=0.2).encode(
        #         x='start:Q',
        #         x2='lower:Q'
        #     )
        #     rule_h = alt.Chart(lh).mark_rect(color='gray', opacity=0.2).encode(
        #         x='higher:Q',
        #         x2='end:Q'
        #     )
        #     chart[case] += rule_l + rule_h
        chart_combo = (chart['heart'] | chart['breath']).configure_axis(
                           labelFontSize=14,
                           titleFontSize=14
                       ).configure_header(
                           labelFontSize=20, title=None)

        placeholder_chart.altair_chart(chart_combo)
endsnippet

snippet altair_heatmap
import altair as alt
import pandas as pd
import streamlit as st

def render_heatmap(img):
	size = int(img.shape[0] / 2)
	x, y = np.meshgrid(range(-size, size), range(-size, size))

	source = pd.DataFrame({'x': x.ravel(),
						   'y': y.ravel(),
						   'mag': img.ravel()
						})
	chart = alt.Chart(source).mark_rect().encode(
		x='x:O',
		y='y:O',
		color=alt.Color('mag:Q',
						sort='descending',
						scale=alt.Scale(scheme='redblue')),
		tooltip=['degC:Q']
	).properties(width=350, height=300)
	st.altair_chart(chart)

endsnippet

snippet pltimshow
norm = plt.Normalize(15, 44)
img = plt.imshow(img, cmap='magma', norm=norm)
sm = matplotlib.cm.ScalarMappable(
cmap='magma',
norm=norm)
sm.set_array(img)
plt.xticks([], [])
plt.yticks([], [])
plt.colorbar(sm)
endsnippet

snippet st_md_br
        placeholder_text2.markdown('<br><br><br><br>', unsafe_allow_html=True)
endsnippet

snippet noq "add noqa pyflakes" i
  #noqa
endsnippet

snippet img_convert
img =  (img - img.min()) / (img.max() - img.min())

array = np.uint8(cm.seismic(img)*255)
st.image(array)

# color  = matplotlib.cm.seismic(img)
im = Image.fromarray(array)
st.image(im)
# img = img * 0.001 - 273.15


converted = cv2.cvtColor(np.uint8((1. - img) * 255), cv2.COLOR_GRAY2BGR)
heatmap = cv2.applyColorMap(converted, cv2.COLORMAP_JET)

st.image(heatmap)

fig = nparray_to_b64(heatmap)[0]
f = io.BytesIO(base64.b64decode(fig.encode()))

st.image(f)
endsnippet

snippet watchdog
import sdnotify
notify = sdnotify.SystemdNotifier()
logger.critical("notify ready")
notify.notify("READY=1")
notify.notify("WATCHDOG=1")
endsnippet

snippet px_line

# px.colors.sequential.Blue to see rgb
ncolors = px.colors.n_colors((247, 252, 253), (0, 68, 27), df.exp.nunique())
ncolors = [f"rgb{c}" for c in ncolors][::-1]

chart = px.line(df, x='quote_date', y='iv_calc', facet_row='underlying_symbol',
                color='exp', color_discrete_sequence=ncolors)
chart.update_traces(line=dict(width=0.5))
endsnippet

snippet px_subfig
chart = px.line(melted, x='quote_date', y='value', color='variable',
                facet_row='underlying_symbol')
chart_2 = px.line(df, x='quote_date', y='iv_calc',
                  facet_row='underlying_symbol')
chart_2.update_traces(yaxis='y2')
subfig = make_subplots(specs=[[{"secondary_y": True}]])
subfig.add_traces(chart.data + chart_2.data)
endsnippet

snippet base_module
from .base_module_object import create_model_module_object

model_module_obj = create_model_module_object(
	load_model=load_model,
	preproc=preproc,
	preproc_one_frame=preproc_one_frame,
	prepare_model=prepare_model,
	name=__name__
)
endsnippet

snippet cuda
os.environ['CUDA_VISIBLE_DEVICES'] = ''
endsnippet


snippet dfstyle

dfs = dfm.style.apply(lambda c: ['background-color: #FF7F50' if i != c['00-WD-read'] and c['00-WD-read'] != 'calibrating' and not pd.isnull(i) else '' for i in c.values], axis=1)
dfs = dfs.apply(lambda c: ['background-color: cornsilk' if i == '00-WD-read' else '' for i in c.index], axis=1)
dfs = dfs.apply(lambda c: ['background-color: grey' if i == 'status_id' else '' for i in c.index], axis=1).hide_index()
endsnippet


snippet img_str
img_str = 'data:image/jpg;base64,' + img_str
endsnippet

snippet git
try:
    import git


    repo = git.Repo(__file__, search_parent_directories=True)

    __commit__ = repo.head.commit.hexsha[:8]
except ModuleNotFoundError:
    __commit__ = ''
endsnippet

snippet crappyhist
def crappyhist(a, bins=50, width=140):
    '''Simple text-based histogram (from stack overflow)'''
    h, b = np.histogram(a, bins)

    for i in range (0, bins):
        print('{:12.5f}  | {:{width}s} {}'.format(
            b[i], 
            '#'*int(width*h[i]/np.amax(h)), 
            h[i], 
            width=width))
    print('{:12.5f}  |'.format(b[bins]))
endsnippet

snippet entropy
def entropy(p:list):
	e = 0
	for p_ in p:
		e -= p_ * np.log2(p_)
	return e
endsnippet

snippet dataprep
from dataprep.datasets import load_dataset
from dataprep.eda import create_report, plot

df = load_dataset("titanic")
# create_report(df).show_browser()
plot(df).show_browser()
endsnippet

snippet thisdir
import os

this_dir = os.path.dirname(os.path.realpath(__file__))
endsnippet

snippet confusion_matrix_s

import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go


def plot_confusion_matrix(confusion_matrix_all, returns_conf_only=False, annotated=True):
    conf_ = confusion_matrix_all
    scores = np.zeros(conf_.shape)
    labels_enumordered = [False, True]
    labels_name_seq = [False, True]
    labels_seq = [False, True]
    for c in range(scores.shape[1]):
        for i in range(scores.shape[0]):
            scores[i][c] = conf_[i, c] / np.sum(conf_[:, c]) * 100
    print(scores)
    confusion_matrix_all = (np.round(confusion_matrix_all / confusion_matrix_all.sum(), 2) * 100)
    remap = [[i for i, j in enumerate(labels_enumordered) if j == e][0]
             for e in (labels_seq)]
    if returns_conf_only:
        return confusion_matrix_all[remap][:, remap],
    confusion_matrix_all = confusion_matrix_all[remap][:, remap]
    scores = scores[remap][:, remap]

    chart = px.imshow(confusion_matrix_all,
                      labels=dict(x="Actual", y="Predicted",
                                  color="Perc %"),
                      x=labels_name_seq,
                      y=labels_name_seq,
                      color_continuous_scale='GnBu'
                      )

    if annotated:
        # text = pd.DataFrame(confusion_matrix_all).stack().apply(lambda x: f'{x:.0f}%').unstack().transpose()
        text = pd.DataFrame(scores).stack().apply(lambda x: f'{x:.0f}%' if x else '').unstack().transpose()
        chart = ff.create_annotated_heatmap(confusion_matrix_all,
                                            annotation_text=text,
                                            colorscale='GnBu')
        chart.layout.update({
            'xaxis': {'constrain': 'domain', 'scaleanchor': 'y',
                      'showticklabels': True,
                      'title': {'text': 'Actual'}},
            'yaxis': {'autorange': 'reversed', 'constrain': 'domain',
                      'showticklabels': True,
                      'title': {'text': 'Predicted'}},
            'coloraxis': {'colorbar': {'title': {'text': 'Perc %'}}}
        })
        heatmap_data = chart.data[0]
        heatmap_data.update({'x': labels_name_seq,
                             'y': labels_name_seq,
            'colorbar': {'title': {'text': 'Perc %'}},
                             'showscale': True})
    chart.update_xaxes(side="top")

    st.write(chart)
    return chart

endsnippet

snippet this_dir
import os
import sys

this_dir = os.path.dirname(os.path.realpath(__file__))

parent_dir = os.path.join(this_dir, '..')

sys.path.append(parent_dir)
sys.path.append(os.path.join(parent_dir, 'app_pkg'))
endsnippet

snippet upsert

def postgres_upsert(table, conn, keys, data_iter):
    from sqlalchemy.dialects.postgresql import insert

    data = [dict(zip(keys, row)) for row in data_iter]

    insert_statement = insert(table.table).values(data)
    upsert_statement = insert_statement.on_conflict_do_update(
        constraint="pk_post_uuid_score_type",
        set_={c.key: c for c in insert_statement.excluded},
    )
    conn.execute(upsert_statement)
endsnippet

snippet to_sql
    df_aer.to_sql(
        "post_scores",
        con=conn,
        schema="ds",
        if_exists="append",
        index=False,
        method=postgres_upsert_post_score,
    )
endsnippet

snippet gbq
## this script is used to look at the posts we are returning from trending-page-prod to the client
## currently its configured to read only college of charleston trending


from google.oauth2 import service_account
from os import path
import datetime as dt
import pandas as pd

import os
import sys

this_dir = os.path.dirname(os.path.realpath(__file__))
parent_dir = os.path.join(this_dir, "..")

sys.path.append(parent_dir)
sys.path.append(os.path.join(parent_dir, "app_pkg"))

from app_pkg.app_utils.connection import get_engine


PROJECT_ID = "annular-garage-257504"
env = "dev"

# -- set CREDENTIALS var this way or set in envvar
# export GOOGLE_APPLICATION_CREDENTIALS=~/hive/annular-garage-257504-f6b3f3884461.json

today = dt.datetime.utcnow().strftime("%Y-%m-%d")
# today_time = dt.datetime(2022, 4, 12, 16, 0, 0).strftime("%Y-%m-%d %H:%M:%S")
today_time = (dt.datetime.utcnow() - dt.timedelta(0, 2 * 3600)).isoformat()


def q_in_bq():
    query_2 = f"""
    SELECT
        r.timestamp,
        r.resource.labels.service_name,
        r.jsonPayload.message.args.ds_trending_page.get_trending_page.ret.user_id as my_user_id,
        -- r.jsonPayload.message.args.ds_trending_page.get_trending_page.ret.meta_info,
        s.type,
        d
    FROM \`annular-garage-257504.ds_api_capture_v5.run_googleapis_com_stderr\` as r
    , unnest(jsonPayload.message.args.ds_trending_page.get_trending_page.ret.sections) as s
    , unnest(s.data) as d
    -- WHERE DATE(timestamp) >= "{today}"
    WHERE timestamp >= "{today_time}"
    and s.type = "people"
    and r.resource.labels.service_name = "ds-trending-page-{env}"
    order by 1 asc
    LIMIT 1500
    """

    df_2 = pd.read_gbq(
        query_2,
        project_id=PROJECT_ID,
        # credentials=CREDENTIALS
    )
    return df_2

endsnippet

snippet st_aggrid
	from st_aggrid import AgGrid
	from st_aggrid.grid_options_builder import GridOptionsBuilder

    gb = GridOptionsBuilder.from_dataframe(df)
    gb.configure_auto_height(autoHeight=True)
    gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=250)
    gb.configure_default_column(editable=True, groupable=True, enableRowGroup=True, aggFunction="count")
    gb.configure_side_bar()
    gb.configure_selection(
        selection_mode="multiple",
        use_checkbox=True,
        rowMultiSelectWithClick=True
    )

    gridOptions = gb.build()

    st.markdown("Select the checkboxes to pick out target rows")
    rows = AgGrid(
            df,
            gridOptions=gridOptions,
            update_mode='MANUAL',  # for auto-update set it to 'SELECTION_CHANGED'
            # fit_columns_on_grid_load=False,
            theme='streamlit',
            enable_enterprise_modules=True
    )
	selected_rows = rows['selected_rows']

endsnippet
